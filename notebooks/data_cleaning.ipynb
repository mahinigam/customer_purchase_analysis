{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02_data_cleaning.ipynb\n",
    "\n",
    "## **Objective:**\n",
    "Perform data cleaning and preprocessing to ensure data quality for analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## **1️⃣ Import Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2️⃣ Set Up Logging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3️⃣ Define File Paths**\n",
    "- Reads the raw dataset from the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_PATH = \"../data/customer_data.csv\"\n",
    "CLEANED_DATA_PATH = \"../data/customer_data_clean.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4️⃣ Load Raw Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"Loads dataset with error handling.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        logging.error(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        logging.info(\"Data successfully loaded.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading data: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5️⃣ Handle Missing Values**\n",
    "- Removes rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_missing_values(df):\n",
    "    \"\"\"Drops rows with missing values.\"\"\"\n",
    "    if df is None:\n",
    "        logging.error(\"No data to clean.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        df.dropna(inplace=True)\n",
    "        logging.info(f\"Missing values removed. Rows before: {len(df)}, After: {len(df)}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error cleaning missing values: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6️⃣ Convert Data Types**\n",
    "- Ensures `purchase_amount` is numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data_types(df):\n",
    "    \"\"\"Converts purchase_amount to numeric type.\"\"\"\n",
    "    if df is None:\n",
    "        logging.error(\"No data to convert.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        df['purchase_amount'] = pd.to_numeric(df['purchase_amount'], errors='coerce')\n",
    "        logging.info(\"Data types converted successfully.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error converting data types: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7️⃣ Feature Engineering**\n",
    "- Adds a log-transformed column for `purchase_amount`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    \"\"\"Creates log-transformed purchase_amount column.\"\"\"\n",
    "    df['purchase_amount_log'] = df['purchase_amount'].apply(lambda x: np.log(x + 1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8️⃣ Sort & Save Cleaned Data**\n",
    "- Sorts by `purchase_amount` and saves the cleaned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cleaned_data(df, file_path):\n",
    "    \"\"\"Saves the cleaned dataset to a CSV file.\"\"\"\n",
    "    df = df.sort_values('purchase_amount', ascending=False)\n",
    "    df.to_csv(file_path, index=False)\n",
    "    logging.info(\"Cleaned data saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **9️⃣ Execute Data Cleaning Process**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(RAW_DATA_PATH)\n",
    "if df is not None:\n",
    "    df = clean_missing_values(df)\n",
    "    df = convert_data_types(df)\n",
    "    df = feature_engineering(df)\n",
    "    save_cleaned_data(df, CLEANED_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Summary & Next Steps**\n",
    "✅ Data has been cleaned and saved.\n",
    "✅ Next, move to `03_eda_analysis.ipynb` for exploratory data analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
